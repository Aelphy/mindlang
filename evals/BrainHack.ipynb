{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn \n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_DATA = '/Users/aelphy/Downloads/files/'\n",
    "\n",
    "open_eyes = []\n",
    "closed_eyes = []\n",
    "for session in os.listdir(EEG_DATA):\n",
    "    if session.startswith('S') and not session.endswith('.txt'):\n",
    "        fopen = pyedflib.EdfReader(osp.join(EEG_DATA, session, session + 'R01.edf'))\n",
    "        fclosed = pyedflib.EdfReader(osp.join(EEG_DATA, session, session + 'R02.edf'))\n",
    "        \n",
    "        for i, f in enumerate([fopen, fclosed]):\n",
    "            n = f.signals_in_file\n",
    "            signal_labels = f.getSignalLabels()\n",
    "            sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "            for j in np.arange(n):\n",
    "                sigbufs[j, :] = f.readSignal(j)\n",
    "            [open_eyes, closed_eyes][i].append(sigbufs[None, ..., :9600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_eyes = np.concatenate(open_eyes)\n",
    "closed_eyes = np.concatenate(closed_eyes)\n",
    "X = np.concatenate([open_eyes, closed_eyes])\n",
    "labels = np.concatenate([np.zeros(len(open_eyes)), np.ones(len(closed_eyes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2).fit_transform(X_train.reshape(len(X_train), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xd3e56d1d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_embedded[:, 0][y_train == 0], X_embedded[:, 1][y_train == 0])\n",
    "plt.scatter(X_embedded[:, 0][y_train == 1], X_embedded[:, 1][y_train == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc1 = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_shape = X_train.shape\n",
    "X_val_shape = X_val.shape\n",
    "X_train_scaled = sc1.fit_transform(X_train.reshape(-1, 1)).reshape(X_train_shape).transpose(0, 2, 1)\n",
    "X_val_scaled = sc1.transform(X_val.reshape(-1, 1)).reshape(X_val_shape).transpose(0, 2, 1)\n",
    "X_train_scaled = X_train.transpose(0, 2, 1)\n",
    "X_val_scaled = X_val.transpose(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tntorch as tn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([torch.Size([163, 1280]),\n",
       "  torch.Size([163, 4000]),\n",
       "  torch.Size([163, 4000]),\n",
       "  torch.Size([163, 1920])],\n",
       " [torch.Size([55, 1280]),\n",
       "  torch.Size([55, 4000]),\n",
       "  torch.Size([55, 4000]),\n",
       "  torch.Size([55, 1920])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = tn.Tensor(X_train.reshape(X_train.shape[0], X_train.shape[1], *[10, 10, 96]), ranks_tt=20, batch=True)\n",
    "tt_val = tn.Tensor(X_val.reshape(X_val.shape[0], X_val.shape[1], *[10, 10, 96]), ranks_tt=20, batch=True)\n",
    "train_cores = [core.reshape(len(core), -1) for core in tt.cores]\n",
    "val_cores = [core.reshape(len(core), -1) for core in tt_val.cores]\n",
    "[core.shape for core in train_cores], [core.shape for core in val_cores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(l, batch_size, shuffle=True):\n",
    "    idxs = np.arange(l)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idxs)\n",
    "\n",
    "    if batch_size > l:\n",
    "        yield idxs\n",
    "        return\n",
    "        \n",
    "    for start_idx in range(0, l, batch_size):\n",
    "        excerpt = idxs[start_idx:start_idx + batch_size]\n",
    "        yield excerpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "class PlainRAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "\n",
    "        super(PlainRAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(PlainRAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                beta2_t = beta2 ** state['step']\n",
    "                N_sma_max = 2 / (1 - beta2) - 1\n",
    "                N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:                    \n",
    "                    step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "                else:\n",
    "                    step_size = group['lr'] / (1 - beta1 ** state['step'])\n",
    "                    p_data_fp32.add_(-step_size, exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class AdamW(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0, warmup = 0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay, warmup = warmup)\n",
    "        super(AdamW, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(AdamW, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                bias_correction1 = 1 - beta1 ** state['step']\n",
    "                bias_correction2 = 1 - beta2 ** state['step']\n",
    "                \n",
    "                if group['warmup'] > state['step']:\n",
    "                    scheduled_lr = 1e-8 + state['step'] * group['lr'] / group['warmup']\n",
    "                else:\n",
    "                    scheduled_lr = group['lr']\n",
    "\n",
    "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
    "                \n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * scheduled_lr, p_data_fp32)\n",
    "\n",
    "                p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TTClassifier(train_cores, 2, device='cpu')\n",
    "optimizer = RAdam(list(clf.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class TTClassifier(nn.Module):\n",
    "    def __init__(self, cores, num_classes, device='cpu'):\n",
    "        super(TTClassifier, self).__init__()\n",
    "                \n",
    "        self.inpts = [None] * len(cores)        \n",
    "        lens = [None] * len(cores)\n",
    "        for i, core in enumerate(cores):\n",
    "            lens[i] = np.prod(core.shape[1:])\n",
    "            self.inpts[i] = nn.Sequential(\n",
    "                nn.Linear(lens[i], 2 * lens[i]),\n",
    "                nn.Tanh()\n",
    "            ).to(device)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(2 * np.sum(lens), 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(500, 250),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(250, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        inpts = [None] * len(x)\n",
    "        for i, core in enumerate(x):\n",
    "            inpts[i] = self.inpts[i](core)\n",
    "\n",
    "        return self.classifier(torch.cat(inpts, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CE(orig, pred):\n",
    "    return torch.nn.functional.cross_entropy(pred, orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\t TRAIN LOSS=0.6968722105026245\n",
      "\t VAL LOSS=0.7033094763755798\n",
      "\t FAILED 0\n",
      "Epoch 2:\n",
      "\t TRAIN LOSS=0.686477255821228\n",
      "\t VAL LOSS=0.6756517291069031\n",
      "\t FAILED 0\n",
      "Epoch 3:\n",
      "\t TRAIN LOSS=0.6521947383880615\n",
      "\t VAL LOSS=0.6520096659660339\n",
      "\t FAILED 0\n",
      "Epoch 4:\n",
      "\t TRAIN LOSS=0.6065455794334411\n",
      "\t VAL LOSS=0.6098774671554565\n",
      "\t FAILED 0\n",
      "Epoch 5:\n",
      "\t TRAIN LOSS=0.5390273213386536\n",
      "\t VAL LOSS=0.5940300226211548\n",
      "\t FAILED 0\n",
      "Epoch 6:\n",
      "\t TRAIN LOSS=0.49159618020057677\n",
      "\t VAL LOSS=0.6322389841079712\n",
      "\t FAILED 0\n",
      "Epoch 7:\n",
      "\t TRAIN LOSS=0.45858129262924197\n",
      "\t VAL LOSS=0.5036295652389526\n",
      "\t FAILED 0\n",
      "Epoch 8:\n",
      "\t TRAIN LOSS=0.4051064014434814\n",
      "\t VAL LOSS=0.6640836000442505\n",
      "\t FAILED 0\n",
      "Epoch 9:\n",
      "\t TRAIN LOSS=0.34034051895141604\n",
      "\t VAL LOSS=0.45472729206085205\n",
      "\t FAILED 0\n",
      "Epoch 10:\n",
      "\t TRAIN LOSS=0.28474880158901217\n",
      "\t VAL LOSS=0.5494940280914307\n",
      "\t FAILED 0\n"
     ]
    }
   ],
   "source": [
    "failed = set()\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "eval_every = 1\n",
    "\n",
    "for j in range(num_epochs):\n",
    "    counter = 0\n",
    "    counter_val = 0\n",
    "    ce_val = 0\n",
    "    ce_train = 0\n",
    "    loss = 0\n",
    "    loss_val = 0\n",
    "\n",
    "    clf.train()\n",
    "    for idxs in iterate_minibatches(len(X_train), batch_size):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        cores = [core[idxs] for core in train_cores]\n",
    "        clf_preds = clf(cores)\n",
    "\n",
    "        ce_loss_batch = compute_CE(torch.tensor(y_train[idxs]).long(), clf_preds)\n",
    "\n",
    "        loss_batch = ce_loss_batch\n",
    "\n",
    "        try:\n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            counter += 1\n",
    "            loss += loss_batch.detach().cpu().numpy()\n",
    "            ce_train += ce_loss_batch.detach().cpu().numpy()\n",
    "        except:\n",
    "            for idx in idxs:\n",
    "                failed.add(idx)\n",
    "\n",
    "    if (j + 1) % eval_every == 0:\n",
    "        clf.eval()\n",
    "        for idxs in iterate_minibatches(len(X_val), batch_size):\n",
    "            cores = [core[idxs] for core in val_cores]\n",
    "            clf_preds = clf(cores)\n",
    "\n",
    "            ce_loss_batch = compute_CE(torch.tensor(y_val[idxs]).long(), clf_preds)\n",
    "\n",
    "            loss_batch = ce_loss_batch\n",
    "\n",
    "            counter_val += 1\n",
    "            loss_val += loss_batch.detach().cpu().numpy()\n",
    "            ce_val += ce_loss_batch.detach().cpu().numpy()\n",
    "            \n",
    "        print('Epoch {}:'.format(j + 1))\n",
    "        print('\\t TRAIN LOSS={}'.format(loss / counter))\n",
    "        print('\\t VAL LOSS={}'.format(loss_val / counter_val))\n",
    "        print('\\t FAILED {}'.format(len(failed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.eval()\n",
    "preds = []\n",
    "labs = []\n",
    "for idxs in iterate_minibatches(len(X_val), batch_size, shuffle=False):\n",
    "    cores = [core[idxs] for core in val_cores]\n",
    "    clf_preds = clf(cores)\n",
    "    preds.append(torch.argmax(torch.softmax(clf_preds, dim=1), dim=1))\n",
    "    labs.append(torch.tensor(y_val[idxs]).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7455)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cat(preds) == torch.cat(labs)).sum().float() / len(torch.cat(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
